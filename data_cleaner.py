#!/usr/bin/env python3
"""
é›·è¾¾æ•°æ®æ¸…æ´—å™¨
æ¸…æ´—ç‚¹äº‘æ•°æ®ï¼Œä¿ç•™x,y,zå’Œå¯†åº¦ä¿¡æ¯ï¼Œ6å¸§èåˆä¸ºä¸€ä¸ªæ ·æœ¬
"""

import json
import os
import numpy as np
from datetime import datetime
import glob

class RadarDataCleaner:
    def __init__(self, data_folder="radar_data"):
        """
        åˆå§‹åŒ–æ•°æ®æ¸…æ´—å™¨
        Args:
            data_folder: æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„
        """
        self.data_folder = data_folder
        self.frames_per_sample = 6  # 6å¸§èåˆä¸ºä¸€ä¸ªæ ·æœ¬
        
    def load_pointcloud_data(self, file_path):
        """åŠ è½½ç‚¹äº‘æ•°æ®æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def extract_pointcloud_features(self, point_data):
        """
        ä»ç‚¹äº‘æ•°æ®ä¸­æå–ç‰¹å¾
        Args:
            point_data: å•å¸§ç‚¹äº‘æ•°æ®
        Returns:
            features: åŒ…å«x,y,zå’Œå¯†åº¦ä¿¡æ¯çš„ç‰¹å¾å­—å…¸
        """
        if not point_data:
            return None
        
        # æå–æ‰€æœ‰ç‚¹çš„åæ ‡
        points = []
        for item in point_data:
            if 'x' in item and 'y' in item and 'z' in item:
                points.append([item['x'], item['y'], item['z']])
        
        if not points:
            return None
        
        points = np.array(points)
        
        # è®¡ç®—ç‰¹å¾
        features = {
            'timestamp': point_data[0].get('timestamp', 0),
            'num_points': len(points),  # ç‚¹äº‘å¯†åº¦
            'x_mean': float(np.mean(points[:, 0])),
            'y_mean': float(np.mean(points[:, 1])),
            'z_mean': float(np.mean(points[:, 2])),
            'x_std': float(np.std(points[:, 0])),
            'y_std': float(np.std(points[:, 1])),
            'z_std': float(np.std(points[:, 2])),
            'x_min': float(np.min(points[:, 0])),
            'y_min': float(np.min(points[:, 1])),
            'z_min': float(np.min(points[:, 2])),
            'x_max': float(np.max(points[:, 0])),
            'y_max': float(np.max(points[:, 1])),
            'z_max': float(np.max(points[:, 2])),
            'spatial_range': float(np.max(points) - np.min(points)),  # ç©ºé—´èŒƒå›´
            'point_density': len(points) / (np.max(points) - np.min(points) + 1e-6)  # ç‚¹äº‘å¯†åº¦
        }
        
        return features
    
    def group_frames_by_time(self, point_data, time_window=1.0):
        """
        æŒ‰æ—¶é—´çª—å£åˆ†ç»„å¸§æ•°æ®
        Args:
            point_data: ç‚¹äº‘æ•°æ®åˆ—è¡¨
            time_window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰
        Returns:
            grouped_frames: åˆ†ç»„åçš„å¸§æ•°æ®
        """
        if not point_data:
            return []
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        sorted_data = sorted(point_data, key=lambda x: x.get('timestamp', 0))
        
        grouped_frames = []
        current_group = []
        last_timestamp = None
        
        for item in sorted_data:
            timestamp = item.get('timestamp', 0)
            
            if last_timestamp is None or (timestamp - last_timestamp) <= time_window:
                current_group.append(item)
            else:
                if current_group:
                    grouped_frames.append(current_group)
                current_group = [item]
            
            last_timestamp = timestamp
        
        # æ·»åŠ æœ€åä¸€ç»„
        if current_group:
            grouped_frames.append(current_group)
        
        return grouped_frames
    
    def create_6_frame_sample(self, frame_groups):
        """
        åˆ›å»º6å¸§èåˆæ ·æœ¬
        Args:
            frame_groups: åˆ†ç»„åçš„å¸§æ•°æ®
        Returns:
            samples: 6å¸§èåˆçš„æ ·æœ¬åˆ—è¡¨
        """
        samples = []
        
        for i in range(0, len(frame_groups), self.frames_per_sample):
            sample_frames = frame_groups[i:i + self.frames_per_sample]
            
            if len(sample_frames) == self.frames_per_sample:
                # æå–æ¯å¸§çš„ç‰¹å¾
                frame_features = []
                for frame_group in sample_frames:
                    features = self.extract_pointcloud_features(frame_group)
                    if features:
                        frame_features.append(features)
                
                if len(frame_features) == self.frames_per_sample:
                    # åˆ›å»ºèåˆæ ·æœ¬
                    sample = {
                        'sample_id': len(samples),
                        'start_timestamp': frame_features[0]['timestamp'],
                        'end_timestamp': frame_features[-1]['timestamp'],
                        'frames': frame_features,
                        # è®¡ç®—æ•´ä½“ç‰¹å¾
                        'total_points': sum(f['num_points'] for f in frame_features),
                        'avg_density': np.mean([f['point_density'] for f in frame_features]),
                        'avg_spatial_range': np.mean([f['spatial_range'] for f in frame_features])
                    }
                    samples.append(sample)
        
        return samples
    
    def clean_and_save_data(self, input_file, output_file):
        """
        æ¸…æ´—å¹¶ä¿å­˜æ•°æ®
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ§¹ æ¸…æ´—æ•°æ®: {input_file}")
        
        # åŠ è½½åŸå§‹æ•°æ®
        raw_data = self.load_pointcloud_data(input_file)
        if not raw_data:
            print(f"âš ï¸  æ–‡ä»¶ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥: {input_file}")
            return
        
        print(f"ğŸ“Š åŸå§‹æ•°æ®: {len(raw_data)} ä¸ªæ•°æ®ç‚¹")
        
        # æŒ‰æ—¶é—´åˆ†ç»„
        frame_groups = self.group_frames_by_time(raw_data)
        print(f"ğŸ“¦ åˆ†ç»„å: {len(frame_groups)} ä¸ªæ—¶é—´çª—å£")
        
        # åˆ›å»º6å¸§æ ·æœ¬
        samples = self.create_6_frame_sample(frame_groups)
        print(f"ğŸ¯ åˆ›å»ºæ ·æœ¬: {len(samples)} ä¸ª6å¸§æ ·æœ¬")
        
        # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(samples, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ æ¸…æ´—åæ•°æ®å·²ä¿å­˜: {output_file}")
        
        return samples
    
    def process_all_data(self):
        """å¤„ç†æ‰€æœ‰æ•°æ®æ–‡ä»¶å¤¹"""
        print("ğŸš€ å¼€å§‹æ¸…æ´—æ‰€æœ‰é›·è¾¾æ•°æ®")
        print("=" * 50)
        
        # æŸ¥æ‰¾æ‰€æœ‰æ•°æ®æ–‡ä»¶å¤¹
        data_dirs = ['sit', 'squat', 'stand']
        
        for data_dir in data_dirs:
            dir_path = os.path.join(self.data_folder, data_dir)
            if not os.path.exists(dir_path):
                print(f"âš ï¸  æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {dir_path}")
                continue
            
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶å¤¹: {data_dir}")
            
            # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
            json_files = glob.glob(os.path.join(dir_path, "**/*.json"), recursive=True)
            
            if not json_files:
                print(f"âš ï¸  æœªæ‰¾åˆ°JSONæ–‡ä»¶: {dir_path}")
                continue
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            output_dir = os.path.join(self.data_folder, f"{data_dir}_cleaned")
            os.makedirs(output_dir, exist_ok=True)
            
            total_samples = 0
            
            for json_file in json_files:
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                rel_path = os.path.relpath(json_file, dir_path)
                output_file = os.path.join(output_dir, f"cleaned_{rel_path}")
                
                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(output_file), exist_ok=True)
                
                # æ¸…æ´—æ•°æ®
                samples = self.clean_and_save_data(json_file, output_file)
                if samples:
                    total_samples += len(samples)
            
            print(f"âœ… {data_dir} å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {total_samples} ä¸ªæ ·æœ¬")
        
        print("\nğŸ‰ æ‰€æœ‰æ•°æ®æ¸…æ´—å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¹ é›·è¾¾æ•°æ®æ¸…æ´—å™¨")
    print("=" * 50)
    
    # åˆ›å»ºæ¸…æ´—å™¨
    cleaner = RadarDataCleaner("radar_data")
    
    # å¤„ç†æ‰€æœ‰æ•°æ®
    cleaner.process_all_data()

if __name__ == "__main__":
    main() 